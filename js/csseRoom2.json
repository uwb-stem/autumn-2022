{
    "csse": [
        {
            "time": "1:00 PM - 1:15 PM",
            "projectId": "csse-2-100",
            "title": "Managing Metric Metadata @ Amazon's Weblab",
            "studentName": "Shehab Ellithy",
            "studentMajor": "CSSE",
            "projectType": "Internship - Amazon",
            "facultyAdvisor": "Dr. Clark Olson",
            "posterLink": "./posters/csse/ellithy-shehab.png",
            "abstract": "For a company the size of Amazon, even the color of a button can make a difference of millions of dollars. So, to centralize the methodologies and testing, Amazon’s Weblab provides APIs and web portals to run A/B tests. Want to know if this button should be top-right or top-left? Create a test and let Weblab handle it. \n\nBecause each team in Amazon has its own metrics (purchases, ad clicks, Prime signups, etc...) and its own way of storing those metrics, it becomes harder to manage and use the data. The responsibility to centralize, clean and organize collected data from the different Amazon teams falls on Amplified Learning, the team I worked with. \n\nI worked towards making this effort easier by creating an API that adds and manages metrics. My project was concerned with Helios, a new system for managing metric metadata. Specifically, I worked on the WeblabMetricAPI which will allow customers to update their metrics’ metadata without going through an Amplified Learning engineer. Helios also provides a single source of truth for the metadata.\n\nMy direct contribution was an initial set of endpoints in the WeblabMetricAPI: Create, Update, List, Enable, and Disable. I also developed a system for the metadata model to stay consistent with the DynamoDB’s model and input validation to ensure that metadata provided by the user is correct. All the APIs are fully unit and integration tested with proper documentation for the next maintainers.\n\nA substantial chunk of effort went to learning Amazon’s internal tools: Brazil, Coral, Code Browser, and CRUX. I also learned about tools/libraries that are used in Java development: Lombok, Mockito, Google’s Guice, Juinit, and Jackson. Finally, I learned how to use Java’s reflection system to ensure model consistency.\n\nSince Helios was a new system, the requirements were still not clearly defined. A significant part of my internship was to gather the requirements from different parties, offer an initial design to the API, and solicit feedback to improve the design.\n\n I quickly learned that requirements are ambiguous, and most people tend to want more features the longer a discussion is held. With the help of my mentor, I restricted the requirements and the design and documented my findings in two Quip documents.\n\nFinally, I added documentation in code and in the Helios wiki to define the scope of the implementation and points that are not done yet."
        },
        {
            "time": "1:15 PM - 1:30 PM",
            "projectId": "csse-2-115",
            "title": "Amazon Internship",
            "studentName": "Amogh Heroor",
            "studentMajor": "CSSE",
            "projectType": "Internship - Amazon",
            "facultyAdvisor": "Dr. Munehiro Fukuda",
            "posterLink": "./posters/csse/heroor-amogh.png",
            "abstract": "For my Capstone project, I underwent an internship at Amazon. This internship was in the advertising org on the Performance and Optimization (PAO) team. The duration of this internship was from June 27th to September 4th. The project I was assigned was called PAOCommonCDK, which is a set of constructs for development. My internship ended with me giving a final presentation and demo to my org, and I received a full-time offer contingent upon graduating.\n\nPAOCommonCDK, as mentioned above, is a CDK construct package. CDK is an AWS product that is used for development in conjunction with AWS services. Amazon uses many AWS services for many of their products, especially in the advertising org. There were 8 constructs in the originally proposed scope. By the end of the internship, I had completed and delivered 3 of these. \n\nA common CDK package designed for a team has three main purposes: faster development due to reduced coding redundancies; a more organized and cohesive codebase; and sets a bar of excellence for development. The constructs that I developed met all three of these purposes. \n\nThe end result of PAOCommonCDK was three CDK constructs. I also had to make sure these constructs had sufficient documentation as the end-users of these constructs would be other developers on the PAO team. As stated above, I demoed these constructs to my team and org, and received quality feedback and approval from them. The project is still alive, and there are many more constructs that can be added to it. Additionally, there is the option to generalize the constructs further such that other teams in the org can use them. \n\nGiven that PAO is a relatively new team to Amazon and the advertising org, it is significant that they have a CDK constructs package while they are still young and creating new services. It will also remain significant as the team gets older and owns more services, as these should all meet a set standard and should be cohesive. \n\nPAOCommonCDK is a project that I am proud of. It will also continue to grow as more and more constructs are needed to be added to it. It will help the PAO team develop and maintain services now and in the future."
        },
        {
            "time": "1:30 PM - 1:45 PM",
            "projectId": "csse-2-130",
            "title": "E-Medical Record: Interface for Viewing Patient Data",
            "studentName": "Daniel Wang",
            "studentMajor": "CSSE",
            "projectType": "Internship - Dr First",
            "facultyAdvisor": "Dr. Laurie Anderson",
            "posterLink": "./posters/csse/wang-daniel.jpg",
            "abstract": "In the current medical field, they face many security and patient data misuse risks. I joined a team tasked with creating an interface for medical professionals such as doctors to store and retrieve information about the patient prescription data and provide a clean interface to manage the users within the system.\n\nOur team followed the Scrum Methodology to produce our solution, we followed the 5-step process of initiation, planning and estimation, implementation, reviewing, and releasing. The internship was a total duration of 14 weeks, the first 6 weeks consisted of front-end dev work, while the last 8 weeks consisted of devops work. A typical workday started at 6:00 AM and ends at 2:30PM. At 8:45AM, our team would hold our daily scrum meetings to update one another on the progress of our tasks and to repeat this cycle till we produced the results the product analyst required.\n\nDuring the first 6 weeks, my contribution to the team consisted of doing front-end dev work, making design changes to certain pages, updating pop up notifications, and implementing the status feature on a user to make it look more intuitive. During these initial 6 weeks, I have also tested various other databases with our interface to test the functionalities to find bugs. For the last 8 weeks of this internship, I worked more on the devops side, where I will be working with the operations team and the developers while using the CI/CD (continuous integration/continuous deployment) pipeline process, to ensure a competitive rate at which code will be released. We are currently in week 10 of our internship, which is week 4 of the devops portion, which has consisted of a lot of research on the devops tools such as Jenkins, SonarQube, Kubernetes, Ansible, Docker, and Terraform. Understanding these tools and how they function together will be an important step in becoming an efficient and effective devops engineer. After the research on the above software, I was briefed on our process of creating builds (Jenkins), and testing the code quality through Sonarqube, and currently, I am doing additional research on Apache Airflow, a new tool we will be incorporating into our devops process, as it will allow us to run jobs associated with a set timer.\n\nOverall, through my front-end dev work at DrFirst, it has drastically improved the UI of the interface. Through my  devops  work,  we’ve  had  successful  deployments  from  the  DEV  to  QA  servers  and  have  improved  our  code coverage from around 30 percent to 60 percent."
        },
        {
            "time": "1:45 PM - 2:00 PM",
            "projectId": "csse-2-145",
            "title": "Marine Collision Adventure Game",
            "studentName": "Brandon Deguia",
            "studentMajor": "CSSE",
            "projectType": "Internship - PNNL",
            "facultyAdvisor": "Dr. Robert Dimpsey",
            "posterLink": "./posters/csse/deguia-brandon.PNG",
            "abstract": "The first question that regulators for tidal energy projects often ask is regarding the risk of collision between marine life and the machinery. The risk of collision between a marine animal and a manmade undersea tidal turbine is relatively low. Pacific Northwest National Laboratory’s Office of Energy Efficiency and Renewable Energy aims to educate the general public on this topic.\n\nThe challenge regarding understanding the risk of collision is the fact that it is difficult to observe close encounters between marine animals and the turbines. Videos of the encounters are not common, and the videos that do exist are in a state that is easily understood by the general public.\n\nThe solution proposed by my team is to create an interactive outreach tool on this topic. The tool will be a 3D, interactive, educational video game that would simulate the underwater environment surrounding tidal turbines. The game will also highlight the various stages of collision and evasion that a marine animal will experience. The user will play as a marine animal (an Atlantic salmon in this iteration) and navigate those stages in a choose-your-own-adventure style manner. \n\nI was put in charge of this project as its lead developer but accompanied by a team of scientists and other developers. I first designed the environment and the gameplay/game flow for the game involving diagrams and flowcharts. After that, I was able to build the game out from that point, which included designing the terrain, implementing player movement via a choice system, programming collision events between 3D models, and constructing the UI to allow the player to direct gameplay. All of this together simulated an accurate undersea recreation, but with the player choosing the outcome for each scenario.\n\nThe result was an experience where the player would navigate two undersea turbines from the perspective of the fish. At the beginning of each scenario, the player will be presented with information about the scenario and will have to make a decision that may have positive or negative consequences, with negative outcomes being unlikely.\n\nThis was an excellent experience to step into the world of game development. As I was the lead developer on the team, I had to make all the decisions regarding how to implement any given feature, and program it mostly myself, but I was never alone thanks to my amazing team that offered constant support. "
        },
        {
            "time": "2:00 PM - 2:15 PM",
            "projectId": "csse-2-200",
            "title": "Internship @ Group-up Industrial Co.",
            "studentName": "Chun-Fu Yang",
            "studentMajor": "CSSE",
            "projectType": "Internsip - Group Up Industrial",
            "facultyAdvisor": "Dr. Robert Dimpsey",
            "posterLink": "./posters/csse/yang-chunfu.JPG",
            "abstract": "During capstone, I built a UI interface and control for control panel on a machine called R2R VRS. It can collect data, and either store or display the data in the control panel in human readable form. For example, it can detect the defect part of a circuit board which might be the a part of the circuit board is not correctly printed,  and the status of the board will be shown as a grid on the panel.\n\n This was done for operators to easily navigate and understand the settings an operations they want to. All of the items are shown in detail and also create a flexibility to adjustment that operator wants to make. For example, they can either use a bar to adjust the size of circuit board to change it with a larger value, or they can use the plus and minus button to increase and decrease the value by one at each click.\n\nWe had all the settings and operations sorted in four different tabs so that not all the functions are show at once. Besides settings, Id of current circuit board would be displayed at top and PLC that is connected would be display on the left. Thus, navigating through different tabs wouldn’t make them disappear. We also had a visual of the circuit board that would change whenever any of the settings related to it gets changed. "
        },
        {
            "time": "2:15 PM - 2:30 PM",
            "projectId": "csse-2-215",
            "title": "Deploying an Improved Amazon Review Credibility Analysis Project",
            "studentName": "Kendall Levy",
            "studentMajor": "CSSE",
            "projectType": "CSS Faculty Research",
            "facultyAdvisor": "Dr. Min Chen",
            "posterLink": "./posters/csse/levy-kendall.png",
            "abstract": "I took code from a previous research project done by a graduate student. I adapted this code to work on a web application. The code took a json file of meta data about Amazon reviews, analyzed it based on several criteria, and output the credibility and results of the criteria. The original code used python scripts with manually written strings of html code written directly in the scripts. The UI was created using Tkinter that opens an html page with the results. \n\n  I started by prototyping the website in Figma. Once the initial prototype was complete, I conducted a usability study with 5 participants. I used the input to update the prototype. Next, I began to work on the web deployment. I stripped the code of the html strings and grouped the code into functions that I could use for the website. I set up a flask app on a Pythonanywhere.com server and wrote the html code for the first page that lets you select which database you would like to look at. I began taking code from the original project and putting it into the flask app to load the dataset. Once this step was complete, I moved on to the next page that lets you select which product you want to look at. After that was the dashboard and the specific graphs pages. \n\n  The specific technical skills I used during this project were creating a dynamic website, creating forms with customized buttons and dropdown selections, as well as adding icons, back buttons, and tables. The languages I used was html, CSS, and python.\n\n   The purpose of this project was to further the development of research towards deployment of possible methods towards analyzing Amazon reviews.\n\n   I was not able to complete all of the functionality desired in the website with the limited time I had, such as a loading bar to show the progress of loading of the database and a search bar for the product selection. However, the end result of the website looks polished and clean. It accurately analyzes the datasets and displays the results clearly.  "
        },
        {
            "time": "2:30 PM - 2:45 PM",
            "projectId": "csse-2-230",
            "title": "Software Engineer Internship at Capital One",
            "studentName": "Xingyu Liu",
            "studentMajor": "CSSE",
            "projectType": "Internship - Capital One",
            "facultyAdvisor": "Dr. Min Chen",
            "posterLink": "./posters/csse/liu-xingyu.png",
            "abstract": "The goal of this capstone project was to gain experience working as a Software Engineer and writing code at a professional level. Software Engineer Interns at Capital One are placed onto a specific team, along with 3-4 other Software Engineer Interns to work on a project with. The intern team is given ownership to a project that the team has created requirements for, where it’s the intern team’s responsibility to design and implement it. Interns also experience working in an agile environment with bi-weekly sprints, with daily stand-ups and end-of-sprint retros.    \n\nThe project completed during this internship was a Python package that would measure and track the performance of an internal data modeling tool at Capital One. This was done so that developers simulate usage and collect performance data when making changes to code. With this tool, developers on the team can store each run data locally or on AWS S3 and visualize it in graph form, creating transparency in performance trends and streamlining model improvement processes.   \n\nAs a result of this project, developers are now able to view performance trends of models release-over-release and while they are developing locally. They can identify areas of improvement to be added onto their next release, which in turn improves the user experience of those using this modeling tool at Capital One. "
        }, 
        {
            "time": "2:45 PM - 3:00 PM",
            "projectId": "csse-2-245",
            "title": "Software Development and Data Analysis Internship at Wind River",
            "studentName": "Collin Niemela",
            "studentMajor": "CSSE",
            "projectType": "Internship - Wind River",
            "facultyAdvisor": "Dr. Min Chen",
            "posterLink": "./posters/csse/niemela-collin.png",
            "abstract": "This past summer I interned at Wind River; a technology company based in California that specializes in mission-critical software. The internship lasted ten weeks and went into topics from both Software Engineering and Data Analysis. The main goal of my internship was to improve the current tracking of website customers by creating a prototype database and a way to connect our data.\n\n  After getting used to the company software, my first two weeks were dedicated to learning JavaScript, Google Analytics, Google Tag Manager, and our website's current setup. Once I familiarized myself with the required tools I began researching and creating a plan to complete my goal. Then I started working on the project, which required me to set up a database in Google Sheets, an automated data retrieval and merging script in Google Apps Script, and a way to get the data using Google Tag Manager. \n\n Work on the project lasted around five weeks and was a challenging task that had lots of trial and error. But after finishing, the project was ready to be analyzed and used for future work on customer tracking. Customer tracking is used to analyze our website and make improvements so that we can increase the likelihood of a purchase. So, a project like the one I worked on is incredibly important to improve product sales.  \n\nWorking for Wind River gave me a deep insight into what it’s like working for a large technology company. I was able to learn new software, how to manage a project, and how to create databases. This experience has taught me so much and will help me greatly in the future. "
        },
        {
            "time": "3:00 PM - 3:15 PM",
            "projectId": "csse-2-300",
            "title": "Fraud Intel Internship",
            "studentName": "Molly Kappes",
            "studentMajor": "CSSE",
            "projectType": "Internship - PNC Bank",
            "facultyAdvisor": "Dr. Min Chen",
            "posterLink": "./posters/csse/kappes-mollyr.jpg",
            "abstract": "As a fraud intelligence intern at PNC Financial Services this past summer, my main responsibility was to create a system that could detect phishing ads from search engines and notify the team for takedown. At this time, an active attacker was posting various phishing ads targeting customers of PNC’s online corporate banking platform, PNC Pinacle®. Before the start of my internship, team members were doing manual searches on a list of terms in order to find the phishing ads. This was a temporary solution, and some customers still managed to click on the ads and give their info away first. The biggest factor at the beginning of the project was the urgency to start producing consistent results. Later on, we focused on extensibility. The other important factor is that every suspected ad still needed manual review by a team member before takedown submission.\n\nTo solve this problem, myself and two other interns created a ‘phishy’ ad detection system using python. We chose python because of the various libraries that made web scraping and then filtering simple to code. At start-up, our system queried a specified search engine on a list of terms hourly, scraped ads, filtered as either ‘known phishy’ or ‘suspected phishy’, then notified the team via webhooks into Mattermost for manual review and takedown. By the end of the summer, we were seeing a significantly decreased frequency in posted ads by the attacker and our project had been shared with security-leadership at PNC. As we were the first group to work on it, this project was designed with the intention of changes and added features, as well as daily use by the team into the future."
        }              
    ]
}